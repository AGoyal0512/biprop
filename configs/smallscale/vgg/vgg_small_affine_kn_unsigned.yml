# Architecture
arch: VGG_Small

# ===== Dataset ===== #
data: /mnt
set: CIFAR10
name: vgg_small_kn_unsigned

# ===== Learning Rate Policy ======== #
optimizer: adam
lr: 0.1
lr_policy: cosine_lr

# ===== Network training config ===== #
epochs: 100
weight_decay: 0.0001
momentum: 0.9
batch_size: 128

# ===== Sparsity =========== #
conv_type: SubnetConv
bn_type: AffineBatchNorm
freeze_weights: True
prune_rate: 0.4
init: kaiming_normal
scale_fan: True

# ===== Hardware setup ===== #
workers: 4
 
